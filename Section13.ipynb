{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a96232-c87a-4b6c-bc6a-1fd5831c0c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using functions in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb81bc9-18f5-4452-83be-38984ac473bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e6b1bd-10e9-4fa0-b024-b4693520374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2021-12-23 08:51:31,738 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        config(\"spark.ui.port\", \"0\").\\\n",
    "        config(\"spark.sql.warehouse.dir\", \"/user/band/warehouse\").\\\n",
    "        enableHiveSupport().\\\n",
    "        appName(\"Functions Spark SQL\").\\\n",
    "        master(\"yarn\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4ea5879-b8c8-41ba-bc8c-bc3a8528b99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|  namespace|\n",
      "+-----------+\n",
      "|band_retail|\n",
      "|    default|\n",
      "|  ordertest|\n",
      "|  retail_db|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b79009d-775f-4683-a7e0-cb431c443138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 09:01:20,366 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "2021-12-23 09:01:20,415 WARN metastore.ObjectStore: Failed to get database testfunction, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS testFunction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e332e60-eef7-4984-8023-0b81751c6206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP DATABASE IF EXISTS testfunction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "890f6a90-c003-4722-8638-c18aa6b5a1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|function             |\n",
      "+---------------------+\n",
      "|!                    |\n",
      "|!=                   |\n",
      "|%                    |\n",
      "|&                    |\n",
      "|*                    |\n",
      "|+                    |\n",
      "|-                    |\n",
      "|/                    |\n",
      "|<                    |\n",
      "|<=                   |\n",
      "|<=>                  |\n",
      "|<>                   |\n",
      "|=                    |\n",
      "|==                   |\n",
      "|>                    |\n",
      "|>=                   |\n",
      "|^                    |\n",
      "|abs                  |\n",
      "|acos                 |\n",
      "|acosh                |\n",
      "|add_months           |\n",
      "|aggregate            |\n",
      "|and                  |\n",
      "|any                  |\n",
      "|approx_count_distinct|\n",
      "|approx_percentile    |\n",
      "|array                |\n",
      "|array_contains       |\n",
      "|array_distinct       |\n",
      "|array_except         |\n",
      "+---------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW FUNCTIONS\").show(30, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a05454f-b15d-422f-a065-7bab6bb52f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|function_desc                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Function: substr                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|Class: org.apache.spark.sql.catalyst.expressions.Substring                                                                                                                                                                                                                                                                                                                                 |\n",
      "|Usage: \\n    substr(str, pos[, len]) - Returns the substring of `str` that starts at `pos` and is of length `len`, or the slice of byte array that starts at `pos` and is of length `len`.\\n\\n    substr(str FROM pos[ FOR len]]) - Returns the substring of `str` that starts at `pos` and is of length `len`, or the slice of byte array that starts at `pos` and is of length `len`.\\n  |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE FUNCTION substr\").show(300, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fea1302-2ae9-4768-aa1d-e2d9126198d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|current_date()|\n",
      "+--------------+\n",
      "|    2021-12-23|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT CURRENT_DATE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ff5a1a6-130a-4353-82c7-7ad2dc7cc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "919f96e7-ad6f-4cea-a1b5-b633b43cb242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE retail_db\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f5dfe18-80bd-4438-bbe1-c7aefe3cdc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>namespace</th><th>tableName</th><th>isTemporary</th></tr>\n",
       "<tr><td>retail_db</td><td>orders</td><td>false</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+---------+-----------+\n",
       "|namespace|tableName|isTemporary|\n",
       "+---------+---------+-----------+\n",
       "|retail_db|   orders|      false|\n",
       "+---------+---------+-----------+"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7715ec89-8fad-42e2-8808-01330a50bc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>col_name</th><th>data_type</th><th>comment</th></tr>\n",
       "<tr><td>order_id</td><td>int</td><td>null</td></tr>\n",
       "<tr><td>order_date</td><td>string</td><td>null</td></tr>\n",
       "<tr><td>order_customer_id</td><td>int</td><td>null</td></tr>\n",
       "<tr><td>order_status</td><td>string</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------+---------+-------+\n",
       "|         col_name|data_type|comment|\n",
       "+-----------------+---------+-------+\n",
       "|         order_id|      int|   null|\n",
       "|       order_date|   string|   null|\n",
       "|order_customer_id|      int|   null|\n",
       "|     order_status|   string|   null|\n",
       "+-----------------+---------+-------+"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88f00536-73e7-4bd3-8094-c86a2edbccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.sql(\"SELECT * FROM orders LIMIT 15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6ff32fc-acd0-4a8a-859b-0a6dc01dff3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4549ef0a-c84b-45e2-bbc1-20682038e8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data.write.format(\"csv\").option(\"header\", True).option(\"sep\", \",\").save(\"/user/band/warehouse/15_first.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a2824e1-c4a7-4eb2-98d9-165eb7b4990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = spark.read.option(\"header\", True).schema(\"order_id INT, order_date STRING, order_customer_id INT, order_status STRING\").csv(\"/user/band/warehouse/15_first.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "711c32c2-87d1-4798-bdd6-7fe30eeab16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------+---------------+\n",
      "|order_id|          order_date|order_customer_id|   order_status|\n",
      "+--------+--------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:...|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:...|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:...|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:...|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:...|            11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:...|             7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:...|             4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:...|             2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:...|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:...|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:...|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:...|             1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:...|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:...|             9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:...|             2568|       COMPLETE|\n",
      "+--------+--------------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "895169c1-d960-4504-89a8-9afd9b2d3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.createOrReplaceTempView(\"orders_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6f8c284d-baf0-4284-ba33-58233b91579b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>col_name</th><th>data_type</th><th>comment</th></tr>\n",
       "<tr><td>order_id</td><td>int</td><td>null</td></tr>\n",
       "<tr><td>order_date</td><td>string</td><td>null</td></tr>\n",
       "<tr><td>order_customer_id</td><td>int</td><td>null</td></tr>\n",
       "<tr><td>order_status</td><td>string</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------+---------+-------+\n",
       "|         col_name|data_type|comment|\n",
       "+-----------------+---------+-------+\n",
       "|         order_id|      int|   null|\n",
       "|       order_date|   string|   null|\n",
       "|order_customer_id|      int|   null|\n",
       "|     order_status|   string|   null|\n",
       "+-----------------+---------+-------+"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE orders_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f951606d-a34b-4db8-95a5-80d79ef98371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------+---------------+\n",
      "|order_id|          order_date|order_customer_id|   order_status|\n",
      "+--------+--------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:...|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:...|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:...|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:...|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:...|            11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:...|             7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:...|             4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:...|             2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:...|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:...|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:...|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:...|             1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:...|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:...|             9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:...|             2568|       COMPLETE|\n",
      "+--------+--------------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM orders_temp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89c0bf97-dade-4e83-af52-f285f9466474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------+---------------+-------------------+\n",
      "|order_id|          order_date|order_customer_id|   order_status|order_status_length|\n",
      "+--------+--------------------+-----------------+---------------+-------------------+\n",
      "|   34565|2014-02-23 00:00:...|             8702|       complete|                  8|\n",
      "|   34566|2014-02-23 00:00:...|             3066|pending_payment|                 15|\n",
      "|   34567|2014-02-23 00:00:...|             7314|suspected_fraud|                 15|\n",
      "|   34568|2014-02-23 00:00:...|             1271|       complete|                  8|\n",
      "|   34569|2014-02-23 00:00:...|            11083|       complete|                  8|\n",
      "|   34570|2014-02-23 00:00:...|             3159|         closed|                  6|\n",
      "|   34571|2014-02-23 00:00:...|             4551|         closed|                  6|\n",
      "|   34572|2014-02-23 00:00:...|             8135|        pending|                  7|\n",
      "|   34573|2014-02-23 00:00:...|             7497|pending_payment|                 15|\n",
      "|   34574|2014-02-23 00:00:...|             1868|        on_hold|                  7|\n",
      "+--------+--------------------+-----------------+---------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT order_id, order_date, order_customer_id,\n",
    "    lower(order_status) AS order_status,\n",
    "    length(order_status) AS order_status_length\n",
    "    FROM orders LIMIT 10\n",
    "\"\"\").show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7b69ab7e-544f-4e69-96cd-c034a12cde32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>order_date</th></tr>\n",
       "<tr><td>2013-07-25</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+\n",
       "|order_date|\n",
       "+----------+\n",
       "|2013-07-25|\n",
       "+----------+"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT concat(year, '-', lpad(month, 2, 0), '-',\n",
    "              lpad(myDate, 2, 0)) AS order_date\n",
    "    FROM\n",
    "    (SELECT 2013 AS year, 7 AS month, 25 AS myDate) q\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dc5acc77-1e7e-4dd0-bd37-c670c077cd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>order_date</th></tr>\n",
       "<tr><td>2013-07-25</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+\n",
       "|order_date|\n",
       "+----------+\n",
       "|2013-07-25|\n",
       "+----------+"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT concat_ws('-', year, lpad(month, 2, 0),\n",
    "              lpad(myDate, 2, 0)) AS order_date\n",
    "    FROM\n",
    "    (SELECT 2013 AS year, 7 AS month, 25 AS myDate) q\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5fe851b5-a35d-4e08-a798-5ffaa3acf156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|result|\n",
      "+------+\n",
      "|  2013|\n",
      "|    07|\n",
      "|    25|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT explode(split('2013-07-25', '-')) AS result\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "10044e3d-bd50-4489-8898-6015dea6e384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  unixtime|\n",
      "+----------+\n",
      "|1556623131|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT to_unix_timestamp('2019-04-30 18:18:51') AS unixtime\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cbe4213c-b808-4740-b5ec-3706afa0ee15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|rnd|flr| cl|\n",
      "+---+---+---+\n",
      "| 11| 10| 11|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    round(10.58) rnd,\n",
    "    floor(10.58) flr,\n",
    "    ceil(10.58) cl\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "917367eb-3344-447f-9c62-52cc67d51278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>abs(-10.5)</th><th>abs(10)</th></tr>\n",
       "<tr><td>10.5</td><td>10</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+-------+\n",
       "|abs(-10.5)|abs(10)|\n",
       "+----------+-------+\n",
       "|      10.5|     10|\n",
       "+----------+-------+"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT abs(-10.5), abs(10)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9b1e37f8-001f-47a1-8ee2-6178fc53f4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|random_int|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT cast(round(rand() * 1) AS int) AS random_int\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0c73ef53-4d55-4ca4-ba75-17051d0a5271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+\n",
      "|function_desc                                                 |\n",
      "+--------------------------------------------------------------+\n",
      "|Function: min                                                 |\n",
      "|Class: org.apache.spark.sql.catalyst.expressions.aggregate.Min|\n",
      "|Usage: min(expr) - Returns the minimum value of `expr`.       |\n",
      "+--------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE FUNCTION MIN\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d2dd0b32-3d2e-47ea-b061-a31b36afe7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+-------+\n",
      "|col_name         |data_type|comment|\n",
      "+-----------------+---------+-------+\n",
      "|order_id         |int      |null   |\n",
      "|order_date       |string   |null   |\n",
      "|order_customer_id|int      |null   |\n",
      "|order_status     |string   |null   |\n",
      "+-----------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE orders\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8683c459-9b48-44d7-8509-3571b44a2e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|title|\n",
      "+-----+\n",
      "|    2|\n",
      "|    3|\n",
      "|    4|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM VALUES (2),3,4 AS tab(title)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "dd4b51ec-8710-4d96-a938-fa346cba4ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|order_customer_id|\n",
      "+-----------------+\n",
      "|             8702|\n",
      "|             3066|\n",
      "|             7314|\n",
      "|             1271|\n",
      "|            11083|\n",
      "|             3159|\n",
      "|             4551|\n",
      "|             8135|\n",
      "|             7497|\n",
      "|             1868|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT order_customer_id FROM orders LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c2c22298-39ac-4974-b305-9e0e4c78b27a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(tb_min)|\n",
      "+-----------+\n",
      "|       1271|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT MIN(tb_min) FROM (SELECT order_customer_id AS tb_min FROM orders LIMIT 10)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a94c1-319e-4a65-b47a-26a1b1db6e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
